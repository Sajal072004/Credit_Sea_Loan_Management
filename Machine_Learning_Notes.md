

# ğŸ“š Machine Learning Exam Notes

## Chapter 1: Linear Regression

### ğŸ”¹ Introduction
Linear Regression is a **supervised machine learning** algorithm used for **predicting continuous numerical values** based on the relationship between dependent and independent variables.

It assumes a linear relationship between the variables, meaning the change in output is proportional to the change in input.

---

### ğŸ”¹ Key Concepts
- **Dependent Variable (Y):** The target we want to predict.
- **Independent Variable (X):** The input features.
- **Line Equation:**  
  \[
  Y = mX + c
  \]
  Where:
  - \( m \) = slope of the line (how steep)
  - \( c \) = y-intercept (where the line crosses the y-axis)

---

### ğŸ”¹ Objective
Minimize the **error** between actual and predicted values using a **loss function**.

Common loss function:
- **Mean Squared Error (MSE)**:  

$$
\text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
$$

Where:
- $y_i$ = actual value  
- $\hat{y}_i$ = predicted value


**Goal:** Find the best \( m \) and \( c \) that minimizes MSE.

---

### ğŸ”¹ Example

**Problem:**  
Predict the price of a house based on its size (in sqft).

| Size (sqft) | Price (in $1000s) |
|:-----------:|:-----------------:|
| 1000        | 300               |
| 1500        | 400               |
| 2000        | 500               |

Linear Regression will learn a line like:  
$$
\text{Price} = 0.2 \times \text{Size} + 100
$$

Thus, for a house of 1800 sqft, predicted price:  
$$
0.2 \times 1800 + 100 = 460
$$  
($460,000)


---

### ğŸ”¹ Important Diagram (Imagine)
```
Price (y-axis)
|
|                        .
|                  .
|             .
|        .
|    .
|________________________ Size (x-axis)
```
â” A straight best-fit line through the data points.

---

### ğŸ”¹ Advantages
- Easy to understand and implement.
- Fast and computationally efficient.
- Works well when the data has a linear relationship.

---

### ğŸ”¹ Disadvantages
- Sensitive to outliers.
- Cannot capture complex non-linear relationships.
- Assumes constant variance of errors (homoscedasticity).

---

### ğŸ”¹ Short Tricks to Remember
âœ… "Best Fit Line" = Linear Regression.  
âœ… "Predict Numbers" = Linear Regression.  
âœ… "Minimize Squared Error" = Goal of Linear Regression.

---

### ğŸ”¹ Quick MCQs (Practice)

**1. What type of output does Linear Regression predict?**  
a) Categories  
b) Continuous Values âœ…  
c) Images  

**2. What is the equation form of Linear Regression?**  
a) \( Y = mX + c \) âœ…  
b) \( Y = X^2 \)  
c) \( Y = e^X \)  

**3. What is the loss function used in Linear Regression?**  
a) Mean Squared Error âœ…  
b) Cross Entropy  
c) Hinge Loss  


Awesome! ğŸš€  
Jumping into **Chapter 2: K-Nearest Neighbors (KNN)** immediately.

Hereâ€™s your complete notes:

---

# ğŸ“š Machine Learning Exam Notes

## Chapter 2: K-Nearest Neighbors (KNN)

### ğŸ”¹ Introduction
K-Nearest Neighbors (KNN) is a **supervised learning algorithm** used for **classification and regression** problems.  
It works by **finding the "k" closest points** to a new input and **making predictions based on their values**.

**Main idea:**  
> "A data point is likely to belong to the same category as its neighbors."

---

### ğŸ”¹ How KNN Works
1. Choose the number \( k \) (number of neighbors).
2. Calculate distance (usually **Euclidean Distance**) between new point and all training data.
3. Pick the **k nearest neighbors**.
4. - **For classification:** Assign the most common class among neighbors.
   - **For regression:** Take the average of neighbors' values.

---

### ğŸ”¹ Important Formulas

**Euclidean Distance Formula:**  
For two points $ (x_1, y_1) $ and $ (x_2, y_2) $,
$$
d = \sqrt{(x_2 - x_1)^2 + (y_2 - y_1)^2}
$$

**Manhattan Distance Formula:**  
$$
d = |x_2 - x_1| + |y_2 - y_1|
$$

---

### ğŸ”¹ Example

Suppose you have:

| Height (cm) | Weight (kg) | Class |
|:-----------:|:-----------:|:-----:|
| 180         | 80          | Male  |
| 160         | 55          | Female|
| 170         | 65          | Male  |

You want to predict for (165, 60).

- Find distances.
- Pick \( k=3 \) nearest neighbors.
- Vote:  
  - Male: 2 votes  
  - Female: 1 vote  

Thus, classified as **Male**.

---

### ğŸ”¹ Important Diagram (Imagine)
```
(X and Y axis showing points)
New point â” find nearest dots â” majority voting
```
â” Circle around the "k" nearest neighbors.

---

### ğŸ”¹ Advantages
- Simple to understand and easy to implement.
- No training phase (lazy learner).
- Works well with smaller datasets.

---

### ğŸ”¹ Disadvantages
- Slow for large datasets (computes distance to every point).
- Sensitive to irrelevant features and the choice of k.
- Curse of dimensionality in high dimensions.

---

### ğŸ”¹ Short Tricks to Remember
âœ… "Neighbors decide my fate!"  
âœ… "No model training â€” only distance calculation!"  
âœ… "Odd k avoids tie situations."

---

### ğŸ”¹ Tips for Choosing 'k'
- Small \( k \): More sensitive to noise.
- Large \( k \): Smoother decision boundaries.
- Generally choose odd \( k \) to avoid ties in classification.

---

### ğŸ”¹ Quick MCQs (Practice)

**1. KNN belongs to which type of learning?**  
a) Supervised âœ…  
b) Unsupervised  
c) Reinforcement  

**2. What does KNN use to make predictions?**  
a) Decision trees  
b) Distances âœ…  
c) Gradients  

**3. What happens if you choose very large \( k \)?**  
a) Overfitting  
b) Underfitting âœ…  
c) No effect  


---

# ğŸ“š Machine Learning Exam Notes

## Chapter 3: Decision Trees

### ğŸ”¹ Introduction
Decision Trees are a **supervised learning** method for both **classification** and **regression**. They split the data into subsets based on feature values, forming a tree of decisions that leads to predictions at the leaves.

---

### ğŸ”¹ Key Concepts
- **Root Node:** Where the tree starts.  
- **Internal Nodes:** Represent feature tests (questions).  
- **Branches:** Outcomes of those tests.  
- **Leaf Nodes:** Final prediction (class label or value).

The tree â€œgrowsâ€ by choosing the feature split that best separates the data at each node.

---

### ğŸ”¹ Splitting Criteria & Formulas

1. **Entropy (Information Gain criterion)**  
   Measures impurity in a node:  
   

$$
H(S) = -\sum_{i=1}^{c} p_i \log_2 p_i
$$

- $p_i$ = proportion of class $i$ in the set.

**Information Gain:**

$$
IG(S, A) = H(S) - \sum_{v \in \text{Values}(A)} \frac{|S_v|}{|S|} H(S_v)
$$


   

2. **Gini Impurity**  
   Alternative to entropy:  
   $G(S) = 1 - \sum_{i=1}^{c} p_i^2$

   Lower Gini means purer nodes.

---

### ğŸ”¹ Example

**Dataset:** Predict whether to **Play Tennis** based on **Outlook**.

| Outlook  | Play? |
|:--------:|:-----:|
| Sunny    | No    |
| Overcast | Yes   |
| Rain     | Yes   |

- **Step 1:** Compute parent entropy.  
- **Step 2:** Calculate entropy for each Outlook value subset.  
- **Step 3:** Compute Information Gain = Parent Entropy â€“ Weighted Child Entropies.  
- **Step 4:** Choose the split with highest IG (e.g., Outlook).

Resulting tree:
```
[Root: Outlook]
 â”œâ”€ Sunny â†’ Leaf: No
 â”œâ”€ Overcast â†’ Leaf: Yes
 â””â”€ Rain â†’ Leaf: Yes
```

---

### ğŸ”¹ Advantages & Disadvantages

**Advantages:**  
- Intuitive and easy to visualize.  
- Handles both numeric and categorical features.

**Disadvantages:**  
- Prone to overfitting (trees can grow too complex).  
- Small changes in data can produce very different trees.

---

### ğŸ”¹ Short Tricks to Remember
âœ… â€œ20 Questions Gameâ€ â€“ each node asks a question.  
âœ… â€œEntropy is chaosâ€ â€“ higher entropy â†’ more mixed classes.

---

### ğŸ”¹ Quick MCQs (Practice)

1. **Which criterion measures impurity using probabilities and logarithms?**  
   a) Gini Impurity  
   b) Entropy âœ…  
   c) Euclidean Distance  

2. **Information Gain is calculated as:**  
   a) Sum of child entropies  
   b) Parent entropy minus weighted child entropies âœ…  
   c) Product of parent and child entropies  

3. **A major risk of unpruned decision trees is:**  
   a) Underfitting  
   b) Overfitting âœ…  
   c) Slow training  

---

---

# ğŸ“š Machine Learning Exam Notes

## Chapter 4: NaÃ¯ve Bayes

### ğŸ”¹ Introduction  
NaÃ¯ve Bayes is a **probabilistic supervised** learning algorithm based on **Bayesâ€™ Theorem**, which assumes that all features are independent given the class label. Itâ€™s widely used for **text classification** (e.g., spam detection).

---

### ğŸ”¹ Key Concepts  
- **Prior Probability** $P(C)$: Probability of class $C$ before seeing data.  
- **Likelihood** $P(X|C)$: Probability of observing features $X$ given class $C$.  
- **Evidence** $P(X)$: Overall probability of observing features $X$.  
- **Posterior Probability** $P(C|X)$: Updated probability of class $C$ after observing $X$.

**Bayesâ€™ Theorem:**  
$$
P(C|X) = \frac{P(X|C)P(C)}{P(X)}
$$

Since $P(X)$ is constant across classes, we compare:  
$$
\hat{C} = \arg\max_{C} P(X|C) P(C)
$$

---

### ğŸ”¹ Example: Spam Detection  
Suppose you have these training counts:

| Feature         | Spam Emails (out of 40) | Ham Emails (out of 60) |
|-----------------|-------------------------|------------------------|
| Contains â€œfreeâ€ | 30                      | 10                     |
| Contains â€œwinâ€  | 20                      | 15                     |

- **P(Spam) = 40/100 = 0.4**  
- **P(Ham) = 60/100 = 0.6**
For a new email that contains both â€œfreeâ€ and â€œwinâ€:

$$
P(\text{Spam}|\text{free, win}) \; \propto \; P(\text{free}|\text{Spam}) \times P(\text{win}|\text{Spam}) \times P(\text{Spam})
= \frac{30}{40} \times \frac{20}{40} \times 0.4 = 0.15
$$

$$
P(\text{Ham}|\text{free, win}) \; \propto \; \frac{10}{60} \times \frac{15}{60} \times 0.6 = 0.025
$$

Since $0.15 > 0.025$, classify as **Spam**.


### ğŸ”¹ Important Diagram (Imagine)
```
            +-------+
Features -> | NaÃ¯ve | -> Class probabilities
            | Bayes |
            +-------+
```
â” Feature independence lets each word vote separately.

---

### ğŸ”¹ Advantages & Disadvantages

**Advantages:**  
- Extremely fast to train and predict.  
- Works well with high-dimensional data (text).  
- Requires relatively small amount of training data.

**Disadvantages:**  
- â€œNaÃ¯veâ€ assumption of feature independence is often violated.  
- Zero probabilities if a word never appears in training (use Laplace smoothing).

---

### ğŸ”¹ Short Tricks to Remember  
âœ… â€œBayes updates your beliefs.â€  
âœ… â€œNaÃ¯ve because features behave independently.â€  
âœ… â€œGood for Spam vs. Ham!â€

---

### ğŸ”¹ Quick MCQs (Practice)

1. **Which assumption does NaÃ¯ve Bayes make?**  
   a) Features are dependent  
   b) Features are independent âœ…  
   c) Classes are continuous  

2. **In Bayesâ€™ Theorem, what is \(P(C)\)?**  
   a) Likelihood  
   b) Prior probability âœ…  
   c) Posterior probability  

3. **When a feature never appears in training for a class, you should use:**  
   a) No adjustment  
   b) Laplace smoothing âœ…  
   c) Increase dataset size  

---


---

# ğŸ“š Machine Learning Exam Notes

## Chapter 5: Support Vector Machines (SVM)

### ğŸ”¹ Introduction  
Support Vector Machines (SVM) are a powerful supervised learning algorithm primarily used for **classification**, although they can be adapted for **regression**. SVM works by finding the **hyperplane** that best separates the data points of different classes in a high-dimensional space.

---

### ğŸ”¹ Key Concepts
- **Hyperplane:** A decision boundary that separates classes.
- **Support Vectors:** Data points that are closest to the hyperplane, and which determine the position of the hyperplane.
- **Margin:** The distance between the hyperplane and the support vectors. SVM maximizes this margin to improve classification.

---

### ğŸ”¹ Formulas

1. **Equation of the Hyperplane:**  
   The hyperplane in $n$-dimensional space is defined by:  
   $$
   w \cdot x + b = 0
   $$  
   Where:  
   - $w$ = weight vector  
   - $b$ = bias  

2. **Maximizing the Margin:**  
   The goal is to maximize the margin:  
   $$
   \text{Margin} = \frac{2}{\|w\|}
   $$  
   The optimization problem is then:  
   $$
   \text{Minimize} \; \frac{1}{2} \|w\|^2
   $$  
   Subject to constraints that the data points are correctly classified.


---

### ğŸ”¹ Example: 2D Classification

Suppose you have two classes of points, **Red** and **Blue**, in a 2D space. SVM will:
1. Find the line (hyperplane) that best separates the two classes.
2. Ensure that the distance from the nearest Red and Blue points to the line is maximized.

For a set of points, SVM might find a line:
```
Red |-----------------------| Blue
```
Where the line divides the two classes with maximum margin.

---

### ğŸ”¹ Important Diagram (Imagine)
```
Support Vectors (red and blue points) determine the Hyperplane.
           /-------------------> Hyperplane
          /          Margin
  Red --|----------------------------|-- Blue
         \       Support Vectors    /
```

---

### ğŸ”¹ Types of SVM

1. **Linear SVM:**  
   Used when the data is linearly separable, i.e., a straight line or hyperplane can perfectly separate the classes.

2. **Non-linear SVM:**  
   When data is not linearly separable, SVM can be adapted using **kernels** to transform data into a higher-dimensional space where it can be linearly separated.

   Common kernels:
   - **Polynomial kernel**
   - **Radial Basis Function (RBF) kernel**

---

### ğŸ”¹ Advantages & Disadvantages

**Advantages:**  
- Works well for high-dimensional data.  
- Effective in cases where there is a clear margin of separation.  
- Robust to overfitting, especially in high-dimensional space.

**Disadvantages:**  
- Computationally expensive, especially with large datasets.  
- Choice of kernel and regularization parameter \(C\) significantly affects performance.  
- Harder to interpret compared to simpler algorithms like decision trees.

---

### ğŸ”¹ Short Tricks to Remember  
âœ… â€œSupport Vectors are critical to the decision boundary.â€  
âœ… â€œMaximize the margin to minimize misclassification.â€  
âœ… â€œLinear vs Non-linear separation â€” use the right kernel.â€

---

### ğŸ”¹ Quick MCQs (Practice)

1. **What is the main goal of SVM?**  
   a) Minimize the distance between points  
   b) Maximize the margin between classes âœ…  
   c) Minimize the number of support vectors  

2. **What does the kernel trick in SVM allow?**  
   a) To map data to a higher-dimensional space for non-linear separation âœ…  
   b) To separate data linearly without a margin  
   c) To speed up training  

3. **What happens if \(C\) is too large in SVM?**  
   a) Too many support vectors  
   b) Higher margin but more misclassification  
   c) Overfitting (tight margin, few misclassifications) âœ…  

---



---

# ğŸ“š Machine Learning Exam Notes

## Chapter 6: Overfitting vs Underfitting

### ğŸ”¹ Introduction  
Overfitting and underfitting are two key concepts in machine learning that describe how well a model generalizes to new data. Balancing these two is crucial for building a model that performs well on unseen data.

---

### ğŸ”¹ Overfitting

**Definition:**  
Overfitting occurs when a model is too complex and captures the **noise** or **random fluctuations** in the training data, instead of generalizing to the underlying trend.

- **Symptoms of Overfitting:**
  - High accuracy on the training data.
  - Low accuracy on the test data.
  
- **Causes of Overfitting:**
  - Too many features relative to the number of training samples.
  - A very complex model (e.g., a deep decision tree or a very high-degree polynomial).
  
**Example:**  
A decision tree that perfectly classifies all training data but fails on new data is overfitting.

---

### ğŸ”¹ Underfitting

**Definition:**  
Underfitting occurs when a model is too simple to capture the underlying trend in the data, leading to poor performance on both the training and test data.

- **Symptoms of Underfitting:**
  - Low accuracy on both training and test data.
  
- **Causes of Underfitting:**
  - Too simple a model (e.g., a linear model for a non-linear problem).
  - Insufficient training (e.g., not enough iterations or too few features).

**Example:**  
A linear regression model applied to data with a non-linear relationship between variables will underfit.

---

### ğŸ”¹ Bias-Variance Tradeoff

- **Bias:** The error introduced by assuming a simplified model. High bias leads to underfitting.
- **Variance:** The error introduced by a model's sensitivity to fluctuations in the training data. High variance leads to overfitting.

The goal is to find the right balance between bias and variance:
- **High Bias** â†’ Underfitting
- **High Variance** â†’ Overfitting

---

### ğŸ”¹ Regularization to Prevent Overfitting

**Regularization** is a technique to prevent overfitting by penalizing large coefficients in the model. The two most common types of regularization are:

1. **L1 Regularization (Lasso):**  
   Adds a penalty proportional to the absolute value of the coefficients. It can lead to sparse models (some coefficients become zero).

   Regularized loss function:  
   $$
   L_{\text{L1}} = \text{Loss} + \lambda \sum |w_i|
   $$

2. **L2 Regularization (Ridge):**  
   Adds a penalty proportional to the square of the coefficients, preventing excessively large values.

   Regularized loss function:  
   $$
   L_{\text{L2}} = \text{Loss} + \lambda \sum w_i^2
   $$


---

### ğŸ”¹ Model Complexity

- **Simple Models** (e.g., linear regression): Tend to **underfit**.
- **Complex Models** (e.g., deep neural networks): Tend to **overfit** unless regularized.

The goal is to find the **right model complexity** that generalizes well to new data.

---

### ğŸ”¹ Techniques to Prevent Overfitting

1. **Cross-Validation**:  
   Helps assess model performance on different subsets of the data to detect overfitting early.
   
2. **Early Stopping**:  
   Stop training as soon as the model starts to overfit (in gradient-based models like neural networks).

3. **Pruning** (for Decision Trees):  
   Remove branches of the tree that have little predictive power to reduce complexity.

4. **Dropout (for Neural Networks):  
   Randomly set a fraction of input units to zero during training to prevent co-adaptation of hidden units.

---

### ğŸ”¹ Advantages & Disadvantages

**Advantages:**  
- Understanding overfitting and underfitting helps optimize model performance.
- Regularization methods can improve generalization and control model complexity.

**Disadvantages:**  
- Finding the right balance between bias and variance can be challenging.
- Complex models might still overfit if not regularized properly.

---

### ğŸ”¹ Short Tricks to Remember  
âœ… â€œOverfitting: Too much complexity.â€  
âœ… â€œUnderfitting: Not enough complexity.â€  
âœ… â€œBalance bias and variance for the best model.â€

---

### ğŸ”¹ Quick MCQs (Practice)

1. **What happens when a model is overfitting?**  
   a) It performs poorly on both training and test data.  
   b) It performs well on training data but poorly on test data. âœ…  
   c) It performs well on test data but poorly on training data.  

2. **What is a common method to prevent overfitting in decision trees?**  
   a) Increase tree depth  
   b) Pruning âœ…  
   c) Increase the number of features  

3. **In the bias-variance tradeoff, what happens when the model complexity increases?**  
   a) Bias increases  
   b) Variance increases âœ…  
   c) Both bias and variance decrease  


---

# ğŸ“š Machine Learning Exam Notes

## Chapter 7: Neural Networks (Perceptron)

### ğŸ”¹ Introduction  
A **perceptron** is the simplest form of a neural networkâ€” a single neuron modelâ€”that can perform **binary classification** on linearly separable data. It forms the building block of more complex neural networks.

---

### ğŸ”¹ Key Concepts  
- **Inputs ($x_i$)**: Features of the data point.  
- **Weights ($w_i$)**: Importance assigned to each feature.  
- **Bias ($b$)**: Adjusts the decision boundary.  
- **Activation Function**: A step function in the basic perceptron, producing an output of 0 or 1.


---

### ğŸ”¹ Mathematical Model & Formulas  

1. **Weighted Sum (Net Input):**  
   $$
   z = \sum_{i=1}^{n} w_i x_i + b
   $$

2. **Activation (Step) Function:**  
   $$
   \hat{y} = 
   \begin{cases}
     1 & \text{if } z \ge 0 \\
     0 & \text{if } z < 0
   \end{cases}
   $$

3. **Perceptron Learning Rule (Weight Update):**  
   $$
   w_i \leftarrow w_i + \eta (y - \hat{y}) x_i
   $$  
   $$
   b \leftarrow b + \eta (y - \hat{y})
   $$  
   Where:  
   - $\eta$ = learning rate  
   - $y$ = true label  
   - $\hat{y}$ = predicted label


---

### ğŸ”¹ Example: AND Gate  
Train a perceptron to learn the logical AND function:

| $x_1$ | $x_2$ | AND ($y$) |
|:-----:|:-----:|:---------:|
| 0     | 0     | 0         |
| 0     | 1     | 0         |
| 1     | 0     | 0         |
| 1     | 1     | 1         |

- Initialize $w_1$, $w_2$, $b$ to small random values.  
- Update weights using the rule until convergence.  
- Final decision boundary separates the single positive (1,1) from others.


---

### ğŸ”¹ Important Diagram (Imagine)
```
 Inputs x1 â”€â”€â”
            â”œâ”€> [ Î£(wÂ·x) + b ] â”€â”€> Activation â”€â”€> Output Å·
 Inputs x2 â”€â”€â”˜
```
â” A single neuron computing a weighted sum and threshold.

---

### ğŸ”¹ Advantages & Disadvantages

**Advantages:**  
- Simple and fast to train.  
- Foundation for deeper neural networks.

**Disadvantages:**  
- Can only solve linearly separable problems.  
- Step activation yields no probability score or gradient, limiting learning techniques.

---

### ğŸ”¹ Short Tricks to Remember  
âœ… â€œPerceptron = one neuron classifier.â€  
âœ… â€œWeight update nudges boundary towards correct side.â€  
âœ… â€œOnly linear separabilityâ€”AND, OR, but not XOR.â€

---

### ğŸ”¹ Quick MCQs (Practice)

1. **What activation function does the basic perceptron use?**  
   a) Sigmoid  
   b) Step Function âœ…  
   c) ReLU  

2. **Which problem can a single perceptron NOT solve?**  
   a) AND  
   b) OR  
   c) XOR âœ…  

3. **In the perceptron learning rule, if the prediction $\hat{y}$ is correct, what happens to the weights?**  
   a) They increase by $\eta x_i$  
   b) They decrease by $\eta x_i$  
   c) They remain unchanged âœ…



# ğŸ“š Machine Learning Exam Notes

## Chapter 8: K-Fold Cross Validation

### ğŸ”¹ Introduction  
Cross validation is a robust technique to **assess model performance** on unseen data. **K-Fold Cross Validation** splits the dataset into \(K\) equal parts (â€œfoldsâ€), ensuring each data point is used for both training and validation.

---

### ğŸ”¹ How It Works  

1. **Split** the data into $K$ equal folds.  
2. **Iterate** $K$ times:  
   - In each iteration, use $K-1$ folds to **train** the model.  
   - Use the **remaining** 1 fold to **validate** the model.  
3. **Average** the performance metrics (e.g., accuracy, MSE) across all $K$ runs.

This gives a more reliable estimate of how the model generalizes.


---

### ğŸ”¹ Example

Suppose you have 100 samples and choose $K=5$.  
- Fold sizes: 20 samples each.  
- Iteration 1: Train on folds 2â€“5 (80 samples), test on fold 1 (20 samples).  
- Iteration 2: Train on folds 1, 3â€“5, test on fold 2.  
- â€¦  
- Iteration 5: Train on folds 1â€“4, test on fold 5.  

You might record accuracies: 88%, 90%, 87%, 89%, 91%.  
**Average accuracy** = $(88 + 90 + 87 + 89 + 91)/5 = 89\%$.

---

### ğŸ”¹ Important Diagram (Imagine)
```
[FOLD 1] [FOLD 2] [FOLD 3] [FOLD 4] [FOLD 5]
   â†˜ Train on 2â€“5 â†’ Validate on 1
   â†˜ Train on 1,3â€“5 â†’ Validate on 2
   â†˜ ... 
   â†˜ Train on 1â€“4 â†’ Validate on 5
```
â” Each fold gets to be the test set exactly once.

---

### ğŸ”¹ Advantages & Disadvantages

**Advantages:**  
- **Reduces bias** from a single train/test split.  
- **Uses all data** for training and validation.  
- Provides a **stable estimate** of model performance.

**Disadvantages:**  
- **Computationally expensive**, especially with large \(K\) or heavy models.  
- **May leak information** if pre-processing (e.g., normalization) isnâ€™t done within each fold.

---

### ğŸ”¹ Short Tricks to Remember  
âœ… â€œRotate the test fold!â€  
âœ… â€œMore folds â†’ less bias, more variance (and compute).â€  
âœ… â€œDo pre-processing inside each fold to avoid leaks.â€

---

### ğŸ”¹ Quick MCQs (Practice)

1. **In 10-Fold Cross Validation on 100 samples, how many samples are in each test fold?**  
   a) 5  
   b) 10 âœ…  
   c) 20  

2. **What is the main benefit of using K-Fold CV over a single train/test split?**  
   a) Faster training  
   b) Reduced bias and variance in performance estimate âœ…  
   c) Simpler to implement  

3. **Which mistake can cause data leakage during K-Fold CV?**  
   a) Shuffling data before splitting  
   b) Performing normalization on the entire dataset before splitting âœ…  
   c) Averaging metrics across folds  


---

# ğŸ“š Machine Learning Exam Notes

## Chapter 9: Important ML Formulas

### ğŸ”¹ Introduction  
Machine Learning relies heavily on mathematical formulas to **measure error**, **quantify impurity**, and **regularize models**. This chapter collects the **key formulas** you need to master.

---

### ğŸ”¹ Key Formulas

1. **Mean Squared Error (MSE)**  
   Measures average squared difference between actual and predicted values.  
   $$
   \text{MSE} = \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2
   $$

2. **Root Mean Squared Error (RMSE)**  
   Square root of MSE, brings error to same units as output.  
   $$
   \text{RMSE} = \sqrt{\text{MSE}} = \sqrt{ \frac{1}{n} \sum_{i=1}^{n} (y_i - \hat{y}_i)^2 }
   $$

3. **Mean Absolute Error (MAE)**  
   Average absolute difference: less sensitive to large errors than MSE.  
   $$
   \text{MAE} = \frac{1}{n} \sum_{i=1}^{n} |y_i - \hat{y}_i|
   $$

4. **Entropy** (Decision Trees)  
   Impurity measure using probabilities and logs.  
   $$
   H(S) = -\sum_{i=1}^{c} p_i \log_2 p_i
   $$

5. **Gini Impurity** (Decision Trees)  
   Alternative impurity:  
   $$
   G(S) = 1 - \sum_{i=1}^{c} p_i^2
   $$

6. **Information Gain**  
   Reduction in entropy after a split on attribute $A$:  
   $$
   IG(S, A) = H(S) - \sum_{v \in \text{Values}(A)} \frac{|S_v|}{|S|}\,H(S_v)
   $$

7. **Bayesâ€™ Theorem** (NaÃ¯ve Bayes)  
   Posterior probability formula:  
   $$
   P(C|X) = \frac{P(X|C)\,P(C)}{P(X)}
   $$

8. **Linear SVM Margin**  
   Margin width for hyperplane $w \cdot x + b = 0$:  
   $$
   \text{Margin} = \frac{2}{\lVert w \rVert}
   $$

9. **Regularization Penalties**  
   - **L2 (Ridge):**  
     $$
     L_{\text{ridge}} = \text{Loss} + \lambda \sum_{i} w_i^2
     $$  
   - **L1 (Lasso):**  
     $$
     L_{\text{lasso}} = \text{Loss} + \lambda \sum_{i} |w_i|
     $$

10. **Principal Component Analysis (PCA)**  
    Compute covariance matrix $ \Sigma $ and eigen-decompose:  
    $$
    \Sigma = \frac{1}{n-1} X^\top X,\quad \Sigma v = \lambda v
    $$  
    Principal components are top eigenvectors $v$.


---

### ğŸ”¹ Example Calculation

**Compute MSE** for actual $\{3, 5, 2\}$ and predicted $\{2, 5, 4\}$:  
$$
\text{MSE} = \frac{(3-2)^2 + (5-5)^2 + (2-4)^2}{3}
= \frac{1 + 0 + 4}{3} = \frac{5}{3} \approx 1.67
$$


---

### ğŸ”¹ Important Diagram (Imagine)
```
                â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
                â”‚    Key ML Formulas Cheat-sheet â”‚
                â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      MSE â†’ squares â†’ average
      MAE â†’ absolutes â†’ average
      Entropy â†’ logs â†’ impurity
      ...
```

---

### ğŸ”¹ Short Tricks to Remember  
- â€œSquare errors â†’ MSE, Root â†’ RMSE.â€  
- â€œAbsolute errors â†’ MAE for robustness.â€  
- â€œEntropy: chaos measure; Gini: probability-based impurity.â€  
- â€œPenalty Î» shrinks weights in regularization.â€

---

### ğŸ”¹ Quick MCQs (Practice)

1. **Which metric gives error in the same units as the target?**  
   a) MSE  
   b) RMSE âœ…  
   c) MAE  

2. **Entropy is zero when:**  
   a) All samples are in one class âœ…  
   b) Classes are equally mixed  
   c) No samples  

3. **L1 regularization adds a penalty of:**  
   a) Sum of squared weights  
   b) Sum of absolute weights âœ…  
   c) Sum of errors  

4. **Information Gain measures:**  
   a) Increase in entropy after split  
   b) Decrease in entropy after split âœ…  
   c) Total entropy  

---


---

# ğŸ“š Machine Learning Exam Notes

## Chapter 10: PCA and LDA

### ğŸ”¹ Introduction  
**PCA (Principal Component Analysis)** and **LDA (Linear Discriminant Analysis)** are both **dimensionality reduction** techniques, but they serve different goals:

- **PCA** is an **unsupervised** method focused on capturing the directions of maximum **variance** in the data.
- **LDA** is a **supervised** method focused on finding directions that maximize **class separability**.

---

### ğŸ”¹ Principal Component Analysis (PCA)

**Objective:** Reduce dimensionality by projecting data onto a lower-dimensional space defined by the top principal components (directions of highest variance).

1. **Standardize** the data (zero mean, unit variance).
2. Compute the **covariance matrix**:
   $$
   \Sigma = \frac{1}{n-1} X^\top X
   $$
3. **Eigen-decompose** the covariance matrix:
   $$
   \Sigma v = \lambda v
   $$
   - $v$: eigenvector (principal component)  
   - $\lambda$: eigenvalue (variance explained)
4. **Select** top $k$ eigenvectors to form the projection matrix.
5. **Project** original data:
   $$
   Z = X V_k
   $$
   Where $V_k$ is matrix of top $k$ eigenvectors.


---

### ğŸ”¹ Linear Discriminant Analysis (LDA)

**Objective:** Reduce dimensionality by projecting data onto directions that maximize the **between-class variance** and minimize the **within-class variance**.

1. Compute **within-class scatter matrix** $S_W$:
   $$
   S_W = \sum_{c=1}^{C} \sum_{x \in D_c} (x - \mu_c)(x - \mu_c)^\top
   $$

2. Compute **between-class scatter matrix** $S_B$:
   $$
   S_B = \sum_{c=1}^{C} N_c (\mu_c - \mu)(\mu_c - \mu)^\top
   $$

3. Solve the **generalized eigenvalue problem**:
   $$
   S_W^{-1} S_B v = \lambda v
   $$

4. **Select** eigenvectors corresponding to the top eigenvalues for projection.


---

### ğŸ”¹ Example

**Dataset:** Two classes (A and B) in 3D space.

- **PCA:** Finds directions where data (both classes) vary the most, regardless of labels.
- **LDA:** Finds direction that best separates A from B.

After PCA:
```
[3D data] â†’ PC1, PC2 projections (max variance axes)
```
After LDA:
```
[3D data] â†’ LD1 projection (max class separation)
```

---

### ğŸ”¹ Advantages & Disadvantages

**PCA:**  
- **Advantages:**  
  - Unsupervised, no class labels needed.  
  - Captures most variance in fewer dimensions.  
- **Disadvantages:**  
  - May not separate classes well (ignores labels).  

**LDA:**  
- **Advantages:**  
  - Optimizes for class separability.  
  - Useful for classification tasks.  
- **Disadvantages:**  
  - Requires class labels.  
  - May overfit if classes have very few samples.

---

### ğŸ”¹ Short Tricks to Remember  
âœ… **PCA = â€œFind variation axes.â€**  
âœ… **LDA = â€œFind separation axes.â€**  
âœ… **PCA unsupervised, LDA supervised.**

---

### ğŸ”¹ Quick MCQs (Practice)

1. **PCA chooses components that:**  
   a) Maximize class separation  
   b) Maximize variance âœ…  
   c) Minimize variance  

2. **LDA requires:**  
   a) No labels  
   b) Class labels âœ…  
   c) Features to be uncorrelated  

3. **Which scatter matrix does LDA maximize?**  
   a) Within-class scatter  
   b) Between-class scatter âœ…  
   c) Covariance matrix  

---


---

# ğŸ“š Machine Learning Exam Notes

## Chapter 11: Ensemble Techniques

### ğŸ”¹ Introduction  
Ensemble methods combine multiple â€œweakâ€ learners to produce a stronger overall model. By aggregating the predictions of several models, ensembles reduce variance (bagging), bias (boosting), or both (stacking).

---

### ğŸ”¹ Key Concepts  
- **Weak Learner:** A model slightly better than random guessing (e.g., a shallow decision tree).  
- **Ensemble:** A group of models whose outputs are combined.  
- **Aggregation Methods:**  
  - **Voting** (classification)  
  - **Averaging** (regression)  
  - **Stacking** (meta-model learns to combine base models)

---

### ğŸ”¹ Types of Ensemble Methods & Formulas

1. **Bagging (Bootstrap Aggregating)**  
   - **Process:** Train each model on a random bootstrap sample (with replacement) of the dataset.  
   - **Prediction (classification):**  
     $$
     \hat{y} = \text{majority\_vote}\bigl(\hat{y}_1, \hat{y}_2, \dots, \hat{y}_m\bigr)
     $$  
   - **Example:** Random Forest (ensemble of decision trees).


2. **Boosting**  
   - **Process:** Sequentially train models, each focusing on the errors of the previous.  
   - **AdaBoost Update Weight:**  
     $$
     w_i \leftarrow w_i \times \exp\bigl(\alpha_t \cdot \mathbb{I}(y_i \neq \hat{y}_i)\bigr)
     $$  
     Where $\alpha_t$ is the modelâ€™s weight based on its error.  
   - **Example:** AdaBoost, Gradient Boosting, XGBoost.


3. **Stacking**  
   - **Process:** Train several base learners on the full dataset; then train a â€œmeta-learnerâ€ on their predictions to learn optimal combinations.  
   - **Meta-Prediction:**  
     $$
     \hat{y} = g\bigl(\hat{y}_1, \hat{y}_2, \dots, \hat{y}_m\bigr)
     $$  
     Where $g$ is the meta-model.


---

### ğŸ”¹ Example: Random Forest Classification

- **Data:** Predict if a customer will churn based on features like tenure, usage, support calls.  
- **Steps:**  
  1. Build 100 decision trees on different bootstrapped samples.  
  2. Each tree votes â€œChurnâ€ or â€œNo Churn.â€  
  3. Final prediction = majority vote.

Random Forest reduces overfitting of single trees and handles nonlinearities.

---

### ğŸ”¹ Important Diagram (Imagine)
```
   Data â”€â”¬â”€> Tree 1 â”€â”
         â”œâ”€> Tree 2 â”€â”¤
         â”œâ”€> ...     â”œâ”€> Majority Vote â†’ Final Prediction
         â””â”€> Tree m â”€â”˜
```
â” Many trees vote together.

---

### ğŸ”¹ Advantages & Disadvantages

**Advantages:**  
- **Bagging:** Lowers variance, robust to overfitting.  
- **Boosting:** Lowers bias, often achieves high accuracy.  
- **Stacking:** Can capture complex relationships between models.

**Disadvantages:**  
- Increased **computational cost** (many models).  
- Harder to **interpret** compared to single models.  
- Overfitting can still occur in boosting if not regularized.

---

### ğŸ”¹ Short Tricks to Remember  
âœ… â€œBagging = Bootstrap + Aggregation â†’ Lower variance.â€  
âœ… â€œBoosting = Sequential focus on errors â†’ Lower bias.â€  
âœ… â€œStacking = Meta-learner â†’ Learn to combine.â€

---

### ğŸ”¹ Quick MCQs (Practice)

1. **Which ensemble method reduces variance by training on bootstrapped samples?**  
   a) Boosting  
   b) Bagging âœ…  
   c) Stacking  

2. **In boosting, each new learner is trained to:**  
   a) Ignore previous errors  
   b) Correct the errors of the previous model âœ…  
   c) Use a different dataset  

3. **Stacking uses a meta-learner to:**  
   a) Generate bootstrapped samples  
   b) Combine base learner predictions âœ…  
   c) Prune decision trees  

---


---

# ğŸ“š Machine Learning Exam Notes

## Chapter 12: New Advancements in ML

### ğŸ”¹ Introduction  
Machine Learning is a rapidly evolving field. Here are some of the **latest advancements** you should know:

1. **Deep Learning Architectures**  
2. **Transfer Learning**  
3. **AutoML**  
4. **Reinforcement Learning Breakthroughs**  
5. **Explainable AI (XAI)**  
6. **Federated Learning**  
7. **Graph Neural Networks (GNNs)**

---

### ğŸ”¹ 1. Deep Learning Architectures

- **Convolutional Neural Networks (CNNs):** Excellent for image data; use convolution and pooling layers.  
- **Recurrent Neural Networks (RNNs) & LSTMs:** Handle sequential data like text and time series.  
- **Transformers:** State-of-the-art for language tasks (e.g., BERT, GPT); rely on self-attention mechanism.

**Key Formula (Backpropagation Update):**  
$$
w \leftarrow w - \eta \frac{\partial L}{\partial w}
$$  
Where $L$ is the loss (e.g., cross-entropy) and $\eta$ is the learning rate.


---

### ğŸ”¹ 2. Transfer Learning

- **Concept:** Use a pre-trained model on a large dataset, then fine-tune on your target task.  
- **Examples:**  
  - **ImageNet** pre-trained CNNs (ResNet, VGG) for new vision tasks.  
  - **BERT**, **GPT** for NLP tasks.

---

### ğŸ”¹ 3. AutoML

- **Objective:** Automate the end-to-end process of model selection, feature engineering, and hyperparameter tuning.  
- **Tools:** Googleâ€™s AutoML, AutoKeras, TPOT.  
- **Benefit:** Democratizes ML, reduces manual effort.

---

### ğŸ”¹ 4. Reinforcement Learning (RL) Breakthroughs

- **Deep Q-Networks (DQN):** Combined Q-learning with deep neural networks for Atari games.  
- **AlphaZero:** Self-play algorithm mastering Chess, Go, and Shogi without human data.  
- **Policy Gradients & Actor-Critic Methods:** Continuous action spaces (e.g., PPO, A3C).

---

### ğŸ”¹ 5. Explainable AI (XAI)

- **Purpose:** Make â€œblack-boxâ€ models interpretable.  
- **Techniques:**  
  - **LIME:** Local surrogate models to explain individual predictions.  
  - **SHAP:** Shapley values from cooperative game theory to assign feature importance.

---

### ğŸ”¹ 6. Federated Learning

- **Concept:** Train models across decentralized devices without sharing raw data (privacy-preserving).  
- **Use Case:** Mobile keyboard prediction, health data analytics.

---

### ğŸ”¹ 7. Graph Neural Networks (GNNs)

- **Objective:** Learn from graph-structured data (social networks, molecules).  
- **Basic Update Rule:**  
  $$
  h_v^{(k+1)} = \sigma \Bigl( \sum_{u \in \mathcal{N}(v)} W^{(k)} h_u^{(k)} + b^{(k)}\Bigr)
  $$  
  Where $h_v$ is node embedding and $\mathcal{N}(v)$ are neighbors.


---

### ğŸ”¹ Advantages & Disadvantages

**Advantages:**  
- Cutting-edge performance across vision, language, and sequential tasks.  
- Transfer learning and AutoML accelerate development.  
- XAI and federated learning address real-world concerns (interpretability, privacy).

**Disadvantages:**  
- High computational cost and resource requirements.  
- Complexity increases risk of overfitting and deployment challenges.  
- XAI methods may oversimplify explanations.

---

### ğŸ”¹ Short Tricks to Remember  
âœ… â€œCNNs for images, RNNs for sequences, Transformers for everything!â€  
âœ… â€œTransfer = reuse knowledge.â€  
âœ… â€œAutoML = ML on autopilot.â€  
âœ… â€œXAI = trust through transparency.â€  
âœ… â€œFederated = train without data leaving.â€  
âœ… â€œGNNs = ML on graphs.â€

---

### ğŸ”¹ Quick MCQs (Practice)

1. **Which architecture uses self-attention for language tasks?**  
   a) RNN  
   b) Transformer âœ…  
   c) CNN  

2. **Federated Learning primarily addresses which concern?**  
   a) Model accuracy  
   b) Data privacy âœ…  
   c) Overfitting  

3. **SHAP is used for:**  
   a) Dimensionality reduction  
   b) Model interpretability âœ…  
   c) Hyperparameter tuning  

4. **Graph Neural Networks operate on:**  
   a) Grid data  
   b) Sequential data  
   c) Graph-structured data âœ…  

---



